{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hail-members/llm-based-services/blob/main/chapter2_%E1%84%8B%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A5%E1%84%86%E1%85%A9%E1%84%83%E1%85%A6%E1%86%AF%E1%84%8B%E1%85%A6_%E1%84%83%E1%85%A2%E1%84%92%E1%85%A1%E1%86%AB_%E1%84%8B%E1%85%B5%E1%84%92%E1%85%A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bag‑of‑Words 예제 코드\n",
        "\n",
        "다음 코드를 Colab의 셀에 복사하여 실행하면 Bag‑of‑Words 모델의 기본 개념을 실습할 수 있습니다.\n"
      ],
      "metadata": {
        "id": "3g7X6t5WHDsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exdf7m-CIoZS",
        "outputId": "9f9986a9-303d-4a76-8291-fa2b17433184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nNOTObdWJRxw",
        "outputId": "d30a9f13-826a-4714-a275-cc7f8631d7f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = corpus[0]\n",
        "text = text.lower()\n",
        "print(text)\n",
        "\n",
        "text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # 구두점 제거\n",
        "print(text)\n",
        "\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(tokens)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LozVY1YQI932",
        "outputId": "24fac45b-eb81-4df6-8aa7-e51f6e03aa1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llm has transformed natural language processing.\n",
            "llm has transformed natural language processing\n",
            "['llm', 'has', 'transformed', 'natural', 'language', 'processing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59hHbnrHGx6_",
        "outputId": "7aea3c0a-4baf-48ec-b7a3-1bef8388d19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Corpus:\n",
            "['llm', 'has', 'transformed', 'natural', 'language', 'processing']\n",
            "['llm', 'such', 'as', 'gpt4', 'and', 'chatgpt', 'demonstrate', 'remarkable', 'understanding', 'and', 'creative', 'capabilities']\n",
            "['prompt', 'engineering', 'plays', 'a', 'key', 'role', 'in', 'enhancing', 'llm', 'performance']\n",
            "['bagofwords', 'models', 'despite', 'their', 'simplicity', 'offer', 'a', 'baseline', 'for', 'feature', 'extraction', 'in', 'text', 'analysis']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 import 및 NLTK 데이터 다운로드\n",
        "import nltk # 자연어 처리를 위한 라이브러리\n",
        "import string # 문자열 처리를 위한 기본 라이브러리\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# NLTK의 punkt 토크나이저 다운로드\n",
        "# 문자열 처리해주는 코드\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# 예제용 문장 데이터 (코퍼스)\n",
        "corpus = [\n",
        "    \"LLM has transformed natural language processing.\",\n",
        "    \"LLM such as GPT-4 and ChatGPT demonstrate remarkable understanding and creative capabilities.\",\n",
        "    \"Prompt engineering plays a key role in enhancing LLM performance.\",\n",
        "    \"Bag-of-words models, despite their simplicity, offer a baseline for feature extraction in text analysis.\"\n",
        "]\n",
        "\n",
        "## 1. Bag-of-Words 구현\n",
        "# 텍스트 전처리 함수: 소문자 변환, 구두점 제거, 토큰화\n",
        "def preprocess(text):\n",
        "    text = text.lower()  # 소문자 변환\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # 구두점 제거\n",
        "    tokens = nltk.word_tokenize(text)  # 토큰화\n",
        "    return tokens\n",
        "\n",
        "# 각 문장을 전처리하여 토큰화된 코퍼스 생성\n",
        "processed_corpus = [preprocess(sentence) for sentence in corpus]\n",
        "print(\"Tokenized Corpus:\")\n",
        "for tokens in processed_corpus:\n",
        "    print(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 전체 코퍼스에서 중복없이 단어목록(vocabulary) 생성 후 정렬\n",
        "vocabulary = sorted(list({token for sentence in processed_corpus for token in sentence}))\n",
        "print(\"\\nVocabulary:\")\n",
        "print(vocabulary)\n",
        "\n",
        "# 각 문장에 대한 Bag-of-Words 벡터 생성 함수\n",
        "def create_bow_vector(tokens, vocabulary):\n",
        "    vector = [0] * len(vocabulary)\n",
        "    for token in tokens:\n",
        "        if token in vocabulary:\n",
        "            idx = vocabulary.index(token)\n",
        "            vector[idx] += 1\n",
        "    return vector\n",
        "\n",
        "# 코퍼스의 각 문장에 대해 Bag-of-Words 벡터를 생성하고 DataFrame으로 변환\n",
        "bow_matrix = [create_bow_vector(tokens, vocabulary) for tokens in processed_corpus]\n",
        "bow_df_manual = pd.DataFrame(bow_matrix, columns=vocabulary)\n",
        "print(\"\\nBag-of-Words Matrix:\")\n",
        "bow_df_manual_ = bow_df_manual.sum()\n",
        "print(bow_df_manual_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlZEdZLoIxU1",
        "outputId": "90057bb4-178a-4506-c2e0-264c0bfb1f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulary:\n",
            "['a', 'analysis', 'and', 'as', 'bagofwords', 'baseline', 'capabilities', 'chatgpt', 'creative', 'demonstrate', 'despite', 'engineering', 'enhancing', 'extraction', 'feature', 'for', 'gpt4', 'has', 'in', 'key', 'language', 'llm', 'models', 'natural', 'offer', 'performance', 'plays', 'processing', 'prompt', 'remarkable', 'role', 'simplicity', 'such', 'text', 'their', 'transformed', 'understanding']\n",
            "\n",
            "Bag-of-Words Matrix:\n",
            "a                2\n",
            "analysis         1\n",
            "and              2\n",
            "as               1\n",
            "bagofwords       1\n",
            "baseline         1\n",
            "capabilities     1\n",
            "chatgpt          1\n",
            "creative         1\n",
            "demonstrate      1\n",
            "despite          1\n",
            "engineering      1\n",
            "enhancing        1\n",
            "extraction       1\n",
            "feature          1\n",
            "for              1\n",
            "gpt4             1\n",
            "has              1\n",
            "in               2\n",
            "key              1\n",
            "language         1\n",
            "llm              3\n",
            "models           1\n",
            "natural          1\n",
            "offer            1\n",
            "performance      1\n",
            "plays            1\n",
            "processing       1\n",
            "prompt           1\n",
            "remarkable       1\n",
            "role             1\n",
            "simplicity       1\n",
            "such             1\n",
            "text             1\n",
            "their            1\n",
            "transformed      1\n",
            "understanding    1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow_df_manual_ = bow_df_manual_/bow_df_manual_.sum()\n",
        "print(bow_df_manual_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh0czsR1NSJS",
        "outputId": "820ad46b-e851-4177-d81d-adc9db76b664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a                0.047619\n",
            "analysis         0.023810\n",
            "and              0.047619\n",
            "as               0.023810\n",
            "bagofwords       0.023810\n",
            "baseline         0.023810\n",
            "capabilities     0.023810\n",
            "chatgpt          0.023810\n",
            "creative         0.023810\n",
            "demonstrate      0.023810\n",
            "despite          0.023810\n",
            "engineering      0.023810\n",
            "enhancing        0.023810\n",
            "extraction       0.023810\n",
            "feature          0.023810\n",
            "for              0.023810\n",
            "gpt4             0.023810\n",
            "has              0.023810\n",
            "in               0.047619\n",
            "key              0.023810\n",
            "language         0.023810\n",
            "llm              0.071429\n",
            "models           0.023810\n",
            "natural          0.023810\n",
            "offer            0.023810\n",
            "performance      0.023810\n",
            "plays            0.023810\n",
            "processing       0.023810\n",
            "prompt           0.023810\n",
            "remarkable       0.023810\n",
            "role             0.023810\n",
            "simplicity       0.023810\n",
            "such             0.023810\n",
            "text             0.023810\n",
            "their            0.023810\n",
            "transformed      0.023810\n",
            "understanding    0.023810\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample 10개짜리 단어들\n",
        "for i in range(10):\n",
        "  print(np.random.choice(bow_df_manual_.index, p=bow_df_manual_.values))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zukL8v3tOLa2",
        "outputId": "c13ea14f-040a-4f92-c675-132275aee02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key\n",
            "their\n",
            "and\n",
            "chatgpt\n",
            "offer\n",
            "transformed\n",
            "simplicity\n",
            "as\n",
            "engineering\n",
            "has\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "코드 설명\n",
        "\n",
        "전처리 및 토큰화:\n",
        "각 문장을 소문자로 변환하고 구두점을 제거한 후 NLTK의 word_tokenize 함수를 사용하여 토큰화합니다.\n",
        "\n",
        "수동 Bag-of-Words 구현:\n",
        "전체 코퍼스에서 고유 단어 목록을 생성한 다음, 각 문장에 대해 해당 단어가 몇 번 등장하는지를 세어 벡터로 만듭니다.\n",
        "\n",
        "그 다음 확률로 만들었습니다.\n"
      ],
      "metadata": {
        "id": "GIC-KmeSHJ1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#N-gram 예제코드\n"
      ],
      "metadata": {
        "id": "0Ms3xiaKPiSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# n-gram 생성 (여기서는 2-gram, 즉 bigram)\n",
        "def generate_ngrams(tokens, n=2):\n",
        "    \"\"\"토큰 리스트에서 n-gram 리스트를 생성하는 함수\"\"\"\n",
        "    return [' '.join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
        "\n",
        "n = 2  # bigram 설정\n",
        "corpus_ngrams = [generate_ngrams(tokens, n) for tokens in processed_corpus]\n",
        "print(\"\\nGenerated n-grams (Bigrams):\")\n",
        "for ngrams in corpus_ngrams:\n",
        "    print(ngrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYfG64L_PeR1",
        "outputId": "c6e8995f-06a5-49b6-904e-a953d40c2550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated n-grams (Bigrams):\n",
            "['llm has', 'has transformed', 'transformed natural', 'natural language', 'language processing']\n",
            "['llm such', 'such as', 'as gpt4', 'gpt4 and', 'and chatgpt', 'chatgpt demonstrate', 'demonstrate remarkable', 'remarkable understanding', 'understanding and', 'and creative', 'creative capabilities']\n",
            "['prompt engineering', 'engineering plays', 'plays a', 'a key', 'key role', 'role in', 'in enhancing', 'enhancing llm', 'llm performance']\n",
            "['bagofwords models', 'models despite', 'despite their', 'their simplicity', 'simplicity offer', 'offer a', 'a baseline', 'baseline for', 'for feature', 'feature extraction', 'extraction in', 'in text', 'text analysis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 코퍼스의 n-gram vocabulary 생성\n",
        "vocabulary_ngrams = sorted(list({ngram for ngrams in corpus_ngrams for ngram in ngrams}))\n",
        "print(\"\\nVocabulary (Bigrams):\")\n",
        "print(vocabulary_ngrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSGyIeuBrfbW",
        "outputId": "fae2cb77-3e23-4b93-ebc4-80d6301d508c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulary (Bigrams):\n",
            "['a baseline', 'a key', 'and chatgpt', 'and creative', 'as gpt4', 'bagofwords models', 'baseline for', 'chatgpt demonstrate', 'creative capabilities', 'demonstrate remarkable', 'despite their', 'engineering plays', 'enhancing llm', 'extraction in', 'feature extraction', 'for feature', 'gpt4 and', 'has transformed', 'in enhancing', 'in text', 'key role', 'language processing', 'llm has', 'llm performance', 'llm such', 'models despite', 'natural language', 'offer a', 'plays a', 'prompt engineering', 'remarkable understanding', 'role in', 'simplicity offer', 'such as', 'text analysis', 'their simplicity', 'transformed natural', 'understanding and']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 문장에 대한 Bag-of-n-grams 벡터 생성 (수동 구현)\n",
        "def create_ngram_vector(ngrams, vocabulary):\n",
        "    vector = [0] * len(vocabulary)\n",
        "    for gram in ngrams:\n",
        "        if gram in vocabulary:\n",
        "            idx = vocabulary.index(gram)\n",
        "            vector[idx] += 1\n",
        "    return vector\n",
        "\n",
        "# 코퍼스의 각 문장에 대해 n-gram 벡터 생성 후 DataFrame으로 변환\n",
        "ngram_matrix = [create_ngram_vector(ngrams, vocabulary_ngrams) for ngrams in corpus_ngrams]\n",
        "ngram_df_manual = pd.DataFrame(ngram_matrix, columns=vocabulary_ngrams)\n",
        "print(\"\\nN-gram Matrix (Manual Implementation):\")\n",
        "print(ngram_df_manual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUgvZJBgrjtl",
        "outputId": "80c2b82a-466b-499b-9045-b9205d39b4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "N-gram Matrix (Manual Implementation):\n",
            "   a baseline  a key  and chatgpt  and creative  as gpt4  bagofwords models  \\\n",
            "0           0      0            0             0        0                  0   \n",
            "1           0      0            1             1        1                  0   \n",
            "2           0      1            0             0        0                  0   \n",
            "3           1      0            0             0        0                  1   \n",
            "\n",
            "   baseline for  chatgpt demonstrate  creative capabilities  \\\n",
            "0             0                    0                      0   \n",
            "1             0                    1                      1   \n",
            "2             0                    0                      0   \n",
            "3             1                    0                      0   \n",
            "\n",
            "   demonstrate remarkable  ...  plays a  prompt engineering  \\\n",
            "0                       0  ...        0                   0   \n",
            "1                       1  ...        0                   0   \n",
            "2                       0  ...        1                   1   \n",
            "3                       0  ...        0                   0   \n",
            "\n",
            "   remarkable understanding  role in  simplicity offer  such as  \\\n",
            "0                         0        0                 0        0   \n",
            "1                         1        0                 0        1   \n",
            "2                         0        1                 0        0   \n",
            "3                         0        0                 1        0   \n",
            "\n",
            "   text analysis  their simplicity  transformed natural  understanding and  \n",
            "0              0                 0                    1                  0  \n",
            "1              0                 0                    0                  1  \n",
            "2              0                 0                    0                  0  \n",
            "3              1                 1                    0                  0  \n",
            "\n",
            "[4 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 n-gram 빈도수 및 확률 계산\n",
        "ngram_total = ngram_df_manual.sum()\n",
        "print(\"\\nTotal N-gram Frequencies:\")\n",
        "print(ngram_total)\n",
        "\n",
        "total_ngrams = ngram_total.sum()\n",
        "ngram_probabilities = ngram_total / total_ngrams\n",
        "print(\"\\nN-gram Probabilities:\")\n",
        "print(ngram_probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLwotfCUrnfp",
        "outputId": "bfb66274-ce87-41e4-91f4-8f70e2f620be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total N-gram Frequencies:\n",
            "a baseline                  1\n",
            "a key                       1\n",
            "and chatgpt                 1\n",
            "and creative                1\n",
            "as gpt4                     1\n",
            "bagofwords models           1\n",
            "baseline for                1\n",
            "chatgpt demonstrate         1\n",
            "creative capabilities       1\n",
            "demonstrate remarkable      1\n",
            "despite their               1\n",
            "engineering plays           1\n",
            "enhancing llm               1\n",
            "extraction in               1\n",
            "feature extraction          1\n",
            "for feature                 1\n",
            "gpt4 and                    1\n",
            "has transformed             1\n",
            "in enhancing                1\n",
            "in text                     1\n",
            "key role                    1\n",
            "language processing         1\n",
            "llm has                     1\n",
            "llm performance             1\n",
            "llm such                    1\n",
            "models despite              1\n",
            "natural language            1\n",
            "offer a                     1\n",
            "plays a                     1\n",
            "prompt engineering          1\n",
            "remarkable understanding    1\n",
            "role in                     1\n",
            "simplicity offer            1\n",
            "such as                     1\n",
            "text analysis               1\n",
            "their simplicity            1\n",
            "transformed natural         1\n",
            "understanding and           1\n",
            "dtype: int64\n",
            "\n",
            "N-gram Probabilities:\n",
            "a baseline                  0.026316\n",
            "a key                       0.026316\n",
            "and chatgpt                 0.026316\n",
            "and creative                0.026316\n",
            "as gpt4                     0.026316\n",
            "bagofwords models           0.026316\n",
            "baseline for                0.026316\n",
            "chatgpt demonstrate         0.026316\n",
            "creative capabilities       0.026316\n",
            "demonstrate remarkable      0.026316\n",
            "despite their               0.026316\n",
            "engineering plays           0.026316\n",
            "enhancing llm               0.026316\n",
            "extraction in               0.026316\n",
            "feature extraction          0.026316\n",
            "for feature                 0.026316\n",
            "gpt4 and                    0.026316\n",
            "has transformed             0.026316\n",
            "in enhancing                0.026316\n",
            "in text                     0.026316\n",
            "key role                    0.026316\n",
            "language processing         0.026316\n",
            "llm has                     0.026316\n",
            "llm performance             0.026316\n",
            "llm such                    0.026316\n",
            "models despite              0.026316\n",
            "natural language            0.026316\n",
            "offer a                     0.026316\n",
            "plays a                     0.026316\n",
            "prompt engineering          0.026316\n",
            "remarkable understanding    0.026316\n",
            "role in                     0.026316\n",
            "simplicity offer            0.026316\n",
            "such as                     0.026316\n",
            "text analysis               0.026316\n",
            "their simplicity            0.026316\n",
            "transformed natural         0.026316\n",
            "understanding and           0.026316\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 확률에 따라 n-gram을 랜덤 샘플링 (예: 10번 샘플링)\n",
        "print(\"\\nSampled n-grams based on probability:\")\n",
        "for i in range(10):\n",
        "    print(np.random.choice(ngram_probabilities.index, p=ngram_probabilities.values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDZ_IArErt7a",
        "outputId": "568f063a-30c4-4beb-a054-68df037c4114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sampled n-grams based on probability:\n",
            "bagofwords models\n",
            "their simplicity\n",
            "llm has\n",
            "bagofwords models\n",
            "a key\n",
            "gpt4 and\n",
            "prompt engineering\n",
            "and creative\n",
            "prompt engineering\n",
            "engineering plays\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "더 길게 한다면?"
      ],
      "metadata": {
        "id": "lxEdYaQOr5Ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 3 # 3-gram 설정\n",
        "corpus_ngrams = [generate_ngrams(tokens, n) for tokens in processed_corpus]\n",
        "print(\"\\nGenerated n-grams (Bigrams):\")\n",
        "for ngrams in corpus_ngrams:\n",
        "    print(ngrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhgO6becr2yl",
        "outputId": "c715f44c-332d-47df-81a4-d8b341b92360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated n-grams (Bigrams):\n",
            "['llm has transformed', 'has transformed natural', 'transformed natural language', 'natural language processing']\n",
            "['llm such as', 'such as gpt4', 'as gpt4 and', 'gpt4 and chatgpt', 'and chatgpt demonstrate', 'chatgpt demonstrate remarkable', 'demonstrate remarkable understanding', 'remarkable understanding and', 'understanding and creative', 'and creative capabilities']\n",
            "['prompt engineering plays', 'engineering plays a', 'plays a key', 'a key role', 'key role in', 'role in enhancing', 'in enhancing llm', 'enhancing llm performance']\n",
            "['bagofwords models despite', 'models despite their', 'despite their simplicity', 'their simplicity offer', 'simplicity offer a', 'offer a baseline', 'a baseline for', 'baseline for feature', 'for feature extraction', 'feature extraction in', 'extraction in text', 'in text analysis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 코퍼스의 n-gram vocabulary 생성\n",
        "vocabulary_ngrams = sorted(list({ngram for ngrams in corpus_ngrams for ngram in ngrams}))\n",
        "print(\"\\nVocabulary (Bigrams):\")\n",
        "print(vocabulary_ngrams)\n",
        "\n",
        "# 코퍼스의 각 문장에 대해 n-gram 벡터 생성 후 DataFrame으로 변환\n",
        "ngram_matrix = [create_ngram_vector(ngrams, vocabulary_ngrams) for ngrams in corpus_ngrams]\n",
        "ngram_df_manual = pd.DataFrame(ngram_matrix, columns=vocabulary_ngrams)\n",
        "print(\"\\nN-gram Matrix (Manual Implementation):\")\n",
        "print(ngram_df_manual)\n",
        "\n",
        "# 전체 n-gram 빈도수 및 확률 계산\n",
        "ngram_total = ngram_df_manual.sum()\n",
        "print(\"\\nTotal N-gram Frequencies:\")\n",
        "print(ngram_total)\n",
        "\n",
        "total_ngrams = ngram_total.sum()\n",
        "ngram_probabilities = ngram_total / total_ngrams\n",
        "print(\"\\nN-gram Probabilities:\")\n",
        "print(ngram_probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EClvDQner80k",
        "outputId": "d34effe2-fd70-4102-f3ee-3dc97f3d191a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulary (Bigrams):\n",
            "['a baseline for', 'a key role', 'and chatgpt demonstrate', 'and creative capabilities', 'as gpt4 and', 'bagofwords models despite', 'baseline for feature', 'chatgpt demonstrate remarkable', 'demonstrate remarkable understanding', 'despite their simplicity', 'engineering plays a', 'enhancing llm performance', 'extraction in text', 'feature extraction in', 'for feature extraction', 'gpt4 and chatgpt', 'has transformed natural', 'in enhancing llm', 'in text analysis', 'key role in', 'llm has transformed', 'llm such as', 'models despite their', 'natural language processing', 'offer a baseline', 'plays a key', 'prompt engineering plays', 'remarkable understanding and', 'role in enhancing', 'simplicity offer a', 'such as gpt4', 'their simplicity offer', 'transformed natural language', 'understanding and creative']\n",
            "\n",
            "N-gram Matrix (Manual Implementation):\n",
            "   a baseline for  a key role  and chatgpt demonstrate  \\\n",
            "0               0           0                        0   \n",
            "1               0           0                        1   \n",
            "2               0           1                        0   \n",
            "3               1           0                        0   \n",
            "\n",
            "   and creative capabilities  as gpt4 and  bagofwords models despite  \\\n",
            "0                          0            0                          0   \n",
            "1                          1            1                          0   \n",
            "2                          0            0                          0   \n",
            "3                          0            0                          1   \n",
            "\n",
            "   baseline for feature  chatgpt demonstrate remarkable  \\\n",
            "0                     0                               0   \n",
            "1                     0                               1   \n",
            "2                     0                               0   \n",
            "3                     1                               0   \n",
            "\n",
            "   demonstrate remarkable understanding  despite their simplicity  ...  \\\n",
            "0                                     0                         0  ...   \n",
            "1                                     1                         0  ...   \n",
            "2                                     0                         0  ...   \n",
            "3                                     0                         1  ...   \n",
            "\n",
            "   offer a baseline  plays a key  prompt engineering plays  \\\n",
            "0                 0            0                         0   \n",
            "1                 0            0                         0   \n",
            "2                 0            1                         1   \n",
            "3                 1            0                         0   \n",
            "\n",
            "   remarkable understanding and  role in enhancing  simplicity offer a  \\\n",
            "0                             0                  0                   0   \n",
            "1                             1                  0                   0   \n",
            "2                             0                  1                   0   \n",
            "3                             0                  0                   1   \n",
            "\n",
            "   such as gpt4  their simplicity offer  transformed natural language  \\\n",
            "0             0                       0                             1   \n",
            "1             1                       0                             0   \n",
            "2             0                       0                             0   \n",
            "3             0                       1                             0   \n",
            "\n",
            "   understanding and creative  \n",
            "0                           0  \n",
            "1                           1  \n",
            "2                           0  \n",
            "3                           0  \n",
            "\n",
            "[4 rows x 34 columns]\n",
            "\n",
            "Total N-gram Frequencies:\n",
            "a baseline for                          1\n",
            "a key role                              1\n",
            "and chatgpt demonstrate                 1\n",
            "and creative capabilities               1\n",
            "as gpt4 and                             1\n",
            "bagofwords models despite               1\n",
            "baseline for feature                    1\n",
            "chatgpt demonstrate remarkable          1\n",
            "demonstrate remarkable understanding    1\n",
            "despite their simplicity                1\n",
            "engineering plays a                     1\n",
            "enhancing llm performance               1\n",
            "extraction in text                      1\n",
            "feature extraction in                   1\n",
            "for feature extraction                  1\n",
            "gpt4 and chatgpt                        1\n",
            "has transformed natural                 1\n",
            "in enhancing llm                        1\n",
            "in text analysis                        1\n",
            "key role in                             1\n",
            "llm has transformed                     1\n",
            "llm such as                             1\n",
            "models despite their                    1\n",
            "natural language processing             1\n",
            "offer a baseline                        1\n",
            "plays a key                             1\n",
            "prompt engineering plays                1\n",
            "remarkable understanding and            1\n",
            "role in enhancing                       1\n",
            "simplicity offer a                      1\n",
            "such as gpt4                            1\n",
            "their simplicity offer                  1\n",
            "transformed natural language            1\n",
            "understanding and creative              1\n",
            "dtype: int64\n",
            "\n",
            "N-gram Probabilities:\n",
            "a baseline for                          0.029412\n",
            "a key role                              0.029412\n",
            "and chatgpt demonstrate                 0.029412\n",
            "and creative capabilities               0.029412\n",
            "as gpt4 and                             0.029412\n",
            "bagofwords models despite               0.029412\n",
            "baseline for feature                    0.029412\n",
            "chatgpt demonstrate remarkable          0.029412\n",
            "demonstrate remarkable understanding    0.029412\n",
            "despite their simplicity                0.029412\n",
            "engineering plays a                     0.029412\n",
            "enhancing llm performance               0.029412\n",
            "extraction in text                      0.029412\n",
            "feature extraction in                   0.029412\n",
            "for feature extraction                  0.029412\n",
            "gpt4 and chatgpt                        0.029412\n",
            "has transformed natural                 0.029412\n",
            "in enhancing llm                        0.029412\n",
            "in text analysis                        0.029412\n",
            "key role in                             0.029412\n",
            "llm has transformed                     0.029412\n",
            "llm such as                             0.029412\n",
            "models despite their                    0.029412\n",
            "natural language processing             0.029412\n",
            "offer a baseline                        0.029412\n",
            "plays a key                             0.029412\n",
            "prompt engineering plays                0.029412\n",
            "remarkable understanding and            0.029412\n",
            "role in enhancing                       0.029412\n",
            "simplicity offer a                      0.029412\n",
            "such as gpt4                            0.029412\n",
            "their simplicity offer                  0.029412\n",
            "transformed natural language            0.029412\n",
            "understanding and creative              0.029412\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 확률에 따라 n-gram을 랜덤 샘플링 (예: 10번 샘플링)\n",
        "print(\"\\nSampled n-grams based on probability:\")\n",
        "for i in range(10):\n",
        "    print(np.random.choice(ngram_probabilities.index, p=ngram_probabilities.values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4_9QiFrsIWA",
        "outputId": "94d51af0-27f8-43a4-ab94-beade7fbfad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sampled n-grams based on probability:\n",
            "such as gpt4\n",
            "llm has transformed\n",
            "key role in\n",
            "feature extraction in\n",
            "and chatgpt demonstrate\n",
            "demonstrate remarkable understanding\n",
            "transformed natural language\n",
            "enhancing llm performance\n",
            "offer a baseline\n",
            "despite their simplicity\n"
          ]
        }
      ]
    }
  ]
}