# main.py
import sys
import os
import time
import threading
import traceback # ì—ëŸ¬ ë¡œê¹…ì„ ìœ„í•´ ì¶”ê°€

# OMP: Error #15 í•´ê²°ì„ ìœ„í•œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ë‹¤ë¥¸ ì„í¬íŠ¸ë³´ë‹¤ ë¨¼ì €)
# ì´ ì„¤ì •ì€ ì—¬ëŸ¬ OpenMP ëŸ°íƒ€ì„ì´ ë¡œë“œë  ë•Œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ë¥¼ íšŒí”¼í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.
# Intelì˜ ê²½ê³ ì— ë”°ë¥´ë©´ ì•ˆì „í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë‚˜, ë§ì€ ê²½ìš° ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

from PyQt6.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,
    QPushButton, QLabel, QTextEdit, QProgressBar, QFileDialog,
    QDialog, QMessageBox
)
from PyQt6.QtCore import Qt, QObject, pyqtSignal, QRunnable, QThreadPool, pyqtSlot
from PyQt6.QtGui import QPixmap, QDragEnterEvent, QDropEvent, QFont

# ì‹¤ì œ OCR ë° LLM ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹œë„ (ëŸ°íƒ€ì„ì—)
try:
    import easyocr
except ImportError:
    easyocr = None
    print("EasyOCR ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'pip install easyocr'ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

try:
    from gpt4all import GPT4All
except ImportError:
    GPT4All = None
    print("GPT4All ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'pip install gpt4all'ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

try:
    import cv2 # ì´ë¯¸ì§€ ë¡œë”© í™•ì¸ì„ ìœ„í•´ OpenCV ì„í¬íŠ¸
except ImportError:
    cv2 = None
    print("OpenCV (cv2) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'pip install opencv-python'ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")


class WorkerSignals(QObject):
    """
    ì›Œì»¤ ìŠ¤ë ˆë“œì—ì„œ GUI ìŠ¤ë ˆë“œë¡œ ì‹œê·¸ë„ì„ ë³´ë‚´ê¸° ìœ„í•œ í´ë˜ìŠ¤.
    - finished: ì‘ì—… ì™„ë£Œ ì‹œ ë°œìƒ
    - error: ì—ëŸ¬ ë°œìƒ ì‹œ ë°œìƒ (ì—ëŸ¬ ë©”ì‹œì§€ ì „ë‹¬)
    - result: ì‘ì—… ê²°ê³¼ ë°œìƒ ì‹œ ë°œìƒ (ì‘ì—… ìœ í˜•, ë°ì´í„° ì „ë‹¬)
    - progress: ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì‹œ ë°œìƒ (ì‘ì—… ìœ í˜•, í¼ì„¼í‹°ì§€ ì „ë‹¬)
    """
    finished = pyqtSignal()
    error = pyqtSignal(str) 
    result = pyqtSignal(str, str)  # task_type, data
    progress = pyqtSignal(str, int) # task_type, percentage

class OCRLLMWorker(QRunnable):
    """
    OCR ë° LLM ì‘ì—…ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìˆ˜í–‰í•˜ëŠ” QRunnable í´ë˜ìŠ¤.
    """
    def __init__(self, task_type, image_path=None, text_input=None,
                 model_name="Meta-Llama-3-8B-Instruct.Q4_0.gguf", 
                 stop_event=None, ocr_reader_instance=None, llm_model_instance=None):
        super().__init__()
        self.signals = WorkerSignals()
        self.task_type = task_type
        self.image_path = image_path
        self.text_input = text_input
        self.model_name = model_name
        self.stop_event = stop_event or threading.Event() # ì¤‘ì§€ ì´ë²¤íŠ¸ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±

        # ë¯¸ë¦¬ ë¡œë“œëœ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© ë˜ëŠ” ì—¬ê¸°ì„œ ë¡œë“œ
        self.ocr_reader = ocr_reader_instance
        self.llm_model = llm_model_instance
        
        self.ocr_text_internal = "" # OCR ê²°ê³¼ë¥¼ ë‚´ë¶€ì ìœ¼ë¡œ ì €ì¥í•˜ì—¬ êµì • ë‹¨ê³„ì—ì„œ ì‚¬ìš©

    @pyqtSlot()
    def run(self):
        try:
            if self.task_type == "ocr_correct":
                if not easyocr:
                    raise ImportError("EasyOCRì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install easyocr'ë¡œ ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                if not GPT4All:
                    raise ImportError("GPT4Allì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install gpt4all'ë¡œ ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                if not cv2:
                    raise ImportError("OpenCV (cv2)ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install opencv-python'ìœ¼ë¡œ ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


                self.signals.progress.emit(self.task_type, 5) # ì‹œì‘
                print("image_path:", self.image_path)
                if not self.image_path or not os.path.exists(self.image_path):
                    raise ValueError("OCRì„ ìœ„í•œ ì´ë¯¸ì§€ ê²½ë¡œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

                # OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¡œë”© í…ŒìŠ¤íŠ¸
                img_cv = cv2.imread(self.image_path)
                if img_cv is None:
                    raise ValueError(f"OpenCVê°€ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.image_path}. íŒŒì¼ ê²½ë¡œ ë˜ëŠ” íŒŒì¼ ì†ìƒ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                
                # 1. OCR ìˆ˜í–‰
                self.signals.progress.emit(self.task_type, 10) # OCR ì‹œì‘ ì•Œë¦¼
                if not self.ocr_reader: # ë¯¸ë¦¬ ë¡œë“œëœ ì¸ìŠ¤í„´ìŠ¤ê°€ ì—†ë‹¤ë©´
                    print("EasyOCR ë¦¬ë”ë¥¼ ì´ ì‘ì—…ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤...")
                    self.ocr_reader = easyocr.Reader(['ko', 'en'], gpu=False) # í•œêµ­ì–´, ì˜ì–´ ì§€ì›
                    print("EasyOCR ë¦¬ë” ë¡œë“œ ì™„ë£Œ.")
                
                if self.stop_event.is_set(): 
                    self.signals.finished.emit()
                    return
                
                # EasyOCRì€ ì´ë¯¸ì§€ ê²½ë¡œ ë˜ëŠ” NumPy ë°°ì—´ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆìŒ
                # ì´ë¯¸ cv2ë¡œ ë¡œë“œí–ˆìœ¼ë¯€ë¡œ, í•´ë‹¹ ê°ì²´ë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìœ¼ë‚˜,
                # EasyOCR ë‚´ë¶€ì—ì„œë„ ê²½ë¡œë¡œ ë¡œë“œí•˜ë¯€ë¡œ ì¼ë‹¨ ê²½ë¡œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©.
                # ë§Œì•½ ë¬¸ì œê°€ ì§€ì†ë˜ë©´ img_cv (BGR) -> RGB ë³€í™˜ í›„ ì „ë‹¬ ì‹œë„ ê°€ëŠ¥
                raw_ocr_results = self.ocr_reader.readtext(self.image_path, detail=0, paragraph=True)
                self.ocr_text_internal = "\n".join(raw_ocr_results)
                
                self.signals.result.emit("ocr_result", self.ocr_text_internal)
                self.signals.progress.emit(self.task_type, 50) # OCR ì™„ë£Œ
                
                if self.stop_event.is_set(): 
                    self.signals.finished.emit()
                    return

                # 2. LLM í…ìŠ¤íŠ¸ êµì •
                self.signals.progress.emit(self.task_type, 55) # LLM êµì • ì‹œì‘ ì•Œë¦¼
                if not self.llm_model: # ë¯¸ë¦¬ ë¡œë“œëœ ì¸ìŠ¤í„´ìŠ¤ê°€ ì—†ë‹¤ë©´
                    print(f"GPT4All ëª¨ë¸ ({self.model_name})ì„ ì´ ì‘ì—…ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤...")
                    self.llm_model = GPT4All(self.model_name, device='cpu', allow_download=True)
                    print("GPT4All ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

                prompt_template_correction = """ë‹¤ìŒì€ ì´ë¯¸ì§€ì—ì„œ ê´‘í•™ ë¬¸ì ì¸ì‹(OCR)ì„ í†µí•´ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì´ í…ìŠ¤íŠ¸ì—ëŠ” ì˜¤ë¥˜ê°€ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›ë³¸ì˜ ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë¬¸ë²•, ì² ì, êµ¬ë‘ì  ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ê³ , í•„ìš”í•œ ê²½ìš° ê°€ë…ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë“¬ì–´ì£¼ì‹­ì‹œì˜¤. ì¶”ê°€ì ì¸ ì„¤ëª…ì´ë‚˜ ì£¼ì„ ì—†ì´ êµì •ëœ í…ìŠ¤íŠ¸ë§Œ ì œê³µí•´ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

OCR í…ìŠ¤íŠ¸:
---
{TEXT_TO_CORRECT}
---

êµì •ëœ í…ìŠ¤íŠ¸:"""
                prompt = prompt_template_correction.format(TEXT_TO_CORRECT=self.ocr_text_internal)
                
                if self.stop_event.is_set(): 
                    self.signals.finished.emit()
                    return
                
                if not self.llm_model:
                     raise RuntimeError("LLM ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (êµì • ë‹¨ê³„).")


                with self.llm_model.chat_session():
                    corrected_text = self.llm_model.generate(prompt, max_tokens=len(self.ocr_text_internal) * 2 + 300, temp=0.6, top_k=40, top_p=0.9, streaming=False)
                
                self.signals.result.emit("corrected_text_result", corrected_text.strip())
                self.signals.progress.emit(self.task_type, 100) # êµì • ì™„ë£Œ

            elif self.task_type == "explain":
                if not GPT4All:
                    raise ImportError("GPT4Allì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install gpt4all'ë¡œ ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                
                self.signals.progress.emit(self.task_type, 10) # í•´ì„¤ ì‹œì‘ ì•Œë¦¼
                if not self.text_input:
                    raise ValueError("í•´ì„¤ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì…ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")

                if not self.llm_model: # ë¯¸ë¦¬ ë¡œë“œëœ ì¸ìŠ¤í„´ìŠ¤ê°€ ì—†ë‹¤ë©´
                    print(f"GPT4All ëª¨ë¸ ({self.model_name})ì„ ì´ ì‘ì—…ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤...")
                    self.llm_model = GPT4All(self.model_name, device='cpu', allow_download=True)
                    print("GPT4All ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
                
                if self.stop_event.is_set(): 
                    self.signals.finished.emit()
                    return

                prompt_template_explanation = """ë‹¤ìŒì€ ë¬¸ì„œì˜ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë¬¸ì„œê°€ ì–´ë–¤ ì¢…ë¥˜ì˜ ë¬¸ì„œì¸ì§€ (ì˜ˆ: ì´ë©”ì¼, ë³´ê³ ì„œ, ê¸°ì‚¬, ë©”ëª¨ ë“±), ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ì§€, ê·¸ë¦¬ê³  ì´ ë¬¸ì„œì˜ ì „ë°˜ì ì¸ ëª©ì ì€ ë¬´ì—‡ìœ¼ë¡œ ë³´ì´ëŠ”ì§€ ê°„ëµí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë¬¸ì„œ ë‚´ìš©:
---
{DOCUMENT_TEXT}
---

ì„¤ëª…:"""
                prompt = prompt_template_explanation.format(DOCUMENT_TEXT=self.text_input)

                if not self.llm_model:
                     raise RuntimeError("LLM ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (í•´ì„¤ ë‹¨ê³„).")
                
                with self.llm_model.chat_session():
                    explanation = self.llm_model.generate(prompt, max_tokens=len(self.text_input) + 500, temp=0.7, top_k=50, top_p=0.95, streaming=False)
                
                self.signals.result.emit("explanation_result", explanation.strip())
                self.signals.progress.emit(self.task_type, 100) # í•´ì„¤ ì™„ë£Œ

        except Exception as e:
            error_msg = f"ì‘ì—… ìœ í˜• '{self.task_type}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\n{type(e).__name__}: {str(e)}\n{traceback.format_exc()}"
            self.signals.error.emit(error_msg)
        finally:
            self.signals.finished.emit()

class ComparisonDialog(QDialog):
    """
    OCR ê²°ê³¼ì™€ LLM ì •ì œ ê²°ê³¼ë¥¼ ë¹„êµí•˜ê³  ì‚¬ìš©ì ê²°ì •ì„ ë°›ëŠ” ëŒ€í™”ìƒì.
    """
    def __init__(self, image_path, ocr_text, refined_text, parent=None):
        super().__init__(parent)
        self.setWindowTitle("ê²°ê³¼ ë¹„êµ ë° ë‹¤ìŒ ë‹¨ê³„ ê²°ì •")
        self.setMinimumSize(900, 700) # ì°½ í¬ê¸° ì¡°ì •

        self.image_path = image_path
        self.ocr_text_content = ocr_text if ocr_text else "OCR ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        self.refined_text_content = refined_text if refined_text else "LLM ì •ì œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        self.final_refined_text = self.refined_text_content # ì‚¬ìš©ìê°€ í¸ì§‘í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸

        main_layout = QVBoxLayout(self)

        # ìƒë‹¨ ì½˜í…ì¸  (ì´ë¯¸ì§€, OCR í…ìŠ¤íŠ¸, ì •ì œ í…ìŠ¤íŠ¸)
        content_layout = QHBoxLayout()

        # 1. ì´ë¯¸ì§€ í‘œì‹œ ì˜ì—­
        image_display_layout = QVBoxLayout()
        image_title = QLabel("ì›ë³¸ ì´ë¯¸ì§€")
        image_title.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_label = QLabel()
        if self.image_path and os.path.exists(self.image_path):
            pixmap = QPixmap(self.image_path)
            self.image_label.setPixmap(pixmap.scaled(300, 400, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation))
        else:
            self.image_label.setText("ì´ë¯¸ì§€ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_label.setMinimumSize(280,380) # ìµœì†Œ í¬ê¸° ì„¤ì •
        image_display_layout.addWidget(image_title)
        image_display_layout.addWidget(self.image_label, 1) # stretch factor
        content_layout.addLayout(image_display_layout, 1) # ë¹„ìœ¨

        # 2. OCR í…ìŠ¤íŠ¸ í‘œì‹œ ì˜ì—­
        ocr_display_layout = QVBoxLayout()
        ocr_title = QLabel("OCR ì¶”ì¶œ í…ìŠ¤íŠ¸ (ì½ê¸° ì „ìš©)")
        ocr_title.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.ocr_text_edit = QTextEdit()
        self.ocr_text_edit.setPlainText(self.ocr_text_content)
        self.ocr_text_edit.setReadOnly(True)
        ocr_display_layout.addWidget(ocr_title)
        ocr_display_layout.addWidget(self.ocr_text_edit, 1)
        content_layout.addLayout(ocr_display_layout, 2)

        # 3. LLM ì •ì œ í…ìŠ¤íŠ¸ í‘œì‹œ ì˜ì—­ (í¸ì§‘ ê°€ëŠ¥)
        refined_display_layout = QVBoxLayout()
        refined_title = QLabel("LLM ì •ì œ í…ìŠ¤íŠ¸ (í¸ì§‘ ê°€ëŠ¥)")
        refined_title.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.refined_text_edit = QTextEdit()
        self.refined_text_edit.setPlainText(self.final_refined_text)
        # self.refined_text_edit.setReadOnly(False) # ê¸°ë³¸ì ìœ¼ë¡œ í¸ì§‘ ê°€ëŠ¥
        refined_display_layout.addWidget(refined_title)
        refined_display_layout.addWidget(self.refined_text_edit, 1)
        content_layout.addLayout(refined_display_layout, 2)
        
        main_layout.addLayout(content_layout)

        # í•˜ë‹¨ ë²„íŠ¼ ì˜ì—­
        button_layout = QHBoxLayout()
        self.redo_button = QPushButton("ğŸ”„ ì¬ì‹œë„ (Redo)")
        self.accept_button = QPushButton("ğŸ‘ ìˆ˜ë½ ë° í•´ì„¤ ìš”ì²­ (Accept)")
        self.cancel_button = QPushButton("âŒ ì·¨ì†Œ (Cancel)")

        button_layout.addStretch()
        button_layout.addWidget(self.redo_button)
        button_layout.addWidget(self.accept_button)
        button_layout.addWidget(self.cancel_button)
        button_layout.addStretch()
        main_layout.addLayout(button_layout)

        # ë²„íŠ¼ ì‹œê·¸ë„ ì—°ê²°
        self.redo_button.clicked.connect(self.on_redo)
        self.accept_button.clicked.connect(self.on_accept)
        self.cancel_button.clicked.connect(self.reject) # QDialogì˜ ê¸°ë³¸ reject ìŠ¬ë¡¯

    def on_redo(self):
        self.done(1) # ì‚¬ìš©ì ì •ì˜ ë°˜í™˜ ì½”ë“œ: ì¬ì‹œë„

    def on_accept(self):
        self.final_refined_text = self.refined_text_edit.toPlainText() # ìˆ˜ë½ ì‹œ í¸ì§‘ëœ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        self.done(2) # ì‚¬ìš©ì ì •ì˜ ë°˜í™˜ ì½”ë“œ: ìˆ˜ë½

    def get_accepted_text(self):
        return self.final_refined_text

class ExplanationDialog(QDialog):
    """
    LLMì˜ ë¬¸ì„œ í•´ì„¤ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ëŒ€í™”ìƒì.
    """
    def __init__(self, explanation_text, parent=None):
        super().__init__(parent)
        self.setWindowTitle("ë¬¸ì„œ í•´ì„¤ ê²°ê³¼")
        self.setMinimumSize(700, 500)

        layout = QVBoxLayout(self)
        self.explanation_text_edit = QTextEdit()
        self.explanation_text_edit.setPlainText(explanation_text if explanation_text else "í•´ì„¤ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        self.explanation_text_edit.setReadOnly(True)
        self.explanation_text_edit.setFont(QFont("Arial", 12)) # í°íŠ¸ í¬ê¸° ì¡°ì ˆ

        layout.addWidget(self.explanation_text_edit)

        close_button = QPushButton("ë‹«ê¸°")
        close_button.clicked.connect(self.accept) # QDialogì˜ ê¸°ë³¸ accept ìŠ¬ë¡¯
        
        button_layout = QHBoxLayout()
        button_layout.addStretch()
        button_layout.addWidget(close_button)
        button_layout.addStretch()
        layout.addLayout(button_layout)


class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("ì´ë¯¸ì§€ ë¶„ì„ ë° ë¬¸ì„œ í•´ì„ê¸°")
        self.setGeometry(100, 100, 1000, 800) # ì°½ í¬ê¸° ì¡°ì •

        # ìƒíƒœ ë³€ìˆ˜
        self.current_image_path = None
        self.raw_ocr_text = ""
        self.current_corrected_text = "" # ComparisonDialogì— ì „ë‹¬ë  í…ìŠ¤íŠ¸
        self.final_accepted_text_for_explanation = "" # ComparisonDialogì—ì„œ ìµœì¢… ìˆ˜ë½ëœ í…ìŠ¤íŠ¸

        # LLM ëª¨ë¸ ì„¤ì •
        self.llm_model_name = "Meta-Llama-3-8B-Instruct.Q4_0.gguf" # ë˜ëŠ” ë‹¤ë¥¸ ì›í•˜ëŠ” ëª¨ë¸
        self.ocr_reader_instance = None 
        self.llm_model_instance = None  
        
        # --- ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ (ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ) ---
        if easyocr:
            print("EasyOCR ë¦¬ë” ë¯¸ë¦¬ ë¡œë”© ì¤‘...")
            try:
                self.ocr_reader_instance = easyocr.Reader(['ko', 'en'], gpu=False) # GPU ì‚¬ìš© ì—¬ë¶€ ì„¤ì •
                print("EasyOCR ë¦¬ë” ë¯¸ë¦¬ ë¡œë“œ ì™„ë£Œ.")
            except Exception as e:
                print(f"EasyOCR ë¯¸ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
                self.ocr_reader_instance = None # ì‹¤íŒ¨ ì‹œ Noneìœ¼ë¡œ ì„¤ì •
        else:
            print("EasyOCR ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ ë¯¸ë¦¬ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if GPT4All:
            print(f"GPT4All ëª¨ë¸ ({self.llm_model_name}) ë¯¸ë¦¬ ë¡œë”© ì¤‘...")
            try:
                self.llm_model_instance = GPT4All(self.llm_model_name, device='cpu', allow_download=True)
                print("GPT4All ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ ì™„ë£Œ.")
            except Exception as e:
                print(f"GPT4All ë¯¸ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
                self.llm_model_instance = None # ì‹¤íŒ¨ ì‹œ Noneìœ¼ë¡œ ì„¤ì •
        else:
            print("GPT4All ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ ë¯¸ë¦¬ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        # --- ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ ë ---


        self.threadpool = QThreadPool()
        self.current_worker_runnable = None # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ QRunnable ê°ì²´
        self.stop_current_worker_event = None # í˜„ì¬ ì›Œì»¤ë¥¼ ì¤‘ì§€í•˜ê¸° ìœ„í•œ ì´ë²¤íŠ¸

        self._init_ui()
        self._connect_signals_slots()
        self.update_status_message("ì´ë¯¸ì§€ íŒŒì¼ì„ ë“œë˜ê·¸ ì•¤ ë“œë¡­í•˜ê±°ë‚˜ 'ì´ë¯¸ì§€ ì„ íƒ' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

    def _init_ui(self):
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QVBoxLayout(central_widget)

        # ìƒë‹¨: ì´ë¯¸ì§€ í‘œì‹œ ë° íŒŒì¼ ì„ íƒ ë²„íŠ¼
        top_controls_layout = QHBoxLayout()
        self.select_image_button = QPushButton("ğŸ“‚ ì´ë¯¸ì§€ íŒŒì¼ ì„ íƒ...")
        top_controls_layout.addWidget(self.select_image_button)
        top_controls_layout.addStretch()
        main_layout.addLayout(top_controls_layout)

        self.image_display_label = QLabel("ì´ë¯¸ì§€ë¥¼ ì—¬ê¸°ì— ë“œë˜ê·¸ ì•¤ ë“œë¡­ í•˜ê±°ë‚˜ ìœ„ ë²„íŠ¼ìœ¼ë¡œ ì„ íƒí•˜ì„¸ìš”.")
        self.image_display_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_display_label.setFrameShape(QLabel.Shape.StyledPanel)
        self.image_display_label.setMinimumHeight(300)
        self.image_display_label.setAcceptDrops(True) # ë“œë˜ê·¸ ì•¤ ë“œë¡­ í™œì„±í™”
        main_layout.addWidget(self.image_display_label, 1) # stretch factor

        # ì¤‘ê°„: ì§„í–‰ë¥  í‘œì‹œì¤„ ë° ìƒíƒœ ë©”ì‹œì§€
        self.progress_bar = QProgressBar()
        self.progress_bar.setValue(0)
        self.progress_bar.setTextVisible(True)
        main_layout.addWidget(self.progress_bar)

        self.status_label = QLabel("ëŒ€ê¸° ì¤‘...")
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        main_layout.addWidget(self.status_label)

        # í•˜ë‹¨: ì£¼ìš” ë™ì‘ ë²„íŠ¼ë“¤
        action_buttons_layout = QHBoxLayout()
        self.analyze_button = QPushButton("1. ì´ë¯¸ì§€ ë¶„ì„ (OCR & ì •ì œ)")
        self.analyze_button.setEnabled(False)
        self.cancel_task_button = QPushButton("í˜„ì¬ ì‘ì—… ì·¨ì†Œ / ì´ˆê¸°í™”")
        
        action_buttons_layout.addWidget(self.analyze_button)
        action_buttons_layout.addWidget(self.cancel_task_button)
        main_layout.addLayout(action_buttons_layout)

    def _connect_signals_slots(self):
        self.select_image_button.clicked.connect(self.open_image_file_dialog)
        self.analyze_button.clicked.connect(self.run_ocr_correction_task)
        self.cancel_task_button.clicked.connect(self.cancel_or_reset_all_processes)

    def update_status_message(self, message):
        self.status_label.setText(message)
        print(f"Status: {message}") # ì½˜ì†”ì—ë„ ì¶œë ¥

    def dragEnterEvent(self, event: QDragEnterEvent):
        mime_data = event.mimeData()
        if mime_data.hasUrls():
            first_url = mime_data.urls()[0]
            if first_url.isLocalFile():
                file_path = first_url.toLocalFile()
                if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):
                    event.acceptProposedAction()
                    return
        event.ignore()

    def dropEvent(self, event: QDropEvent):
        file_path = event.mimeData().urls()[0].toLocalFile()
        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):
            self.load_image_and_prepare_analysis(file_path)
            event.accept()
        else:
            event.ignore()

    def open_image_file_dialog(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "ì´ë¯¸ì§€ íŒŒì¼ ì„ íƒ", "", "ì´ë¯¸ì§€ íŒŒì¼ (*.png *.jpg *.jpeg)")
        if file_path:
            self.load_image_and_prepare_analysis(file_path)

    def load_image_and_prepare_analysis(self, image_path):
        self.cancel_current_worker_if_running() # ìƒˆ ì´ë¯¸ì§€ ë¡œë“œ ì‹œ ì´ì „ ì‘ì—… ì¤‘ì§€
        
        self.current_image_path = image_path
        pixmap = QPixmap(image_path)
        self.image_display_label.setPixmap(pixmap.scaled(self.image_display_label.size(),
                                                 Qt.AspectRatioMode.KeepAspectRatio,
                                                 Qt.TransformationMode.SmoothTransformation))
        self.raw_ocr_text = ""
        self.current_corrected_text = ""
        self.final_accepted_text_for_explanation = ""
        self.progress_bar.setValue(0)
        
        self.analyze_button.setEnabled(True)
        self.update_status_message(f"ì´ë¯¸ì§€ ë¡œë“œ: {os.path.basename(image_path)}. 'ì´ë¯¸ì§€ ë¶„ì„' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

    def _start_background_worker(self, task_type, **kwargs):
        if self.current_worker_runnable is not None:
            self.update_status_message("ì˜¤ë¥˜: ë‹¤ë¥¸ ì‘ì—…ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. í˜„ì¬ ì‘ì—…ì„ ì·¨ì†Œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return

        self.progress_bar.setValue(0)
        self.stop_current_worker_event = threading.Event()

        self.current_worker_runnable = OCRLLMWorker(
            task_type=task_type,
            model_name=self.llm_model_name,
            stop_event=self.stop_current_worker_event,
            ocr_reader_instance=self.ocr_reader_instance, # ë¯¸ë¦¬ ë¡œë“œëœ ì¸ìŠ¤í„´ìŠ¤ ì „ë‹¬
            llm_model_instance=self.llm_model_instance,  # ë¯¸ë¦¬ ë¡œë“œëœ ì¸ìŠ¤í„´ìŠ¤ ì „ë‹¬
            **kwargs
        )
        
        self.current_worker_runnable.signals.result.connect(self.handle_worker_result)
        self.current_worker_runnable.signals.progress.connect(self.handle_worker_progress)
        self.current_worker_runnable.signals.finished.connect(self.handle_worker_finished)
        self.current_worker_runnable.signals.error.connect(self.handle_worker_error)
        
        self.threadpool.start(self.current_worker_runnable)
        self.set_buttons_for_task_running_state(True)
        self.update_status_message(f"{task_type.replace('_',' ').title()} ì‘ì—… ì‹œì‘...")

    def run_ocr_correction_task(self):
        if not self.current_image_path:
            self.update_status_message("ì˜¤ë¥˜: ë¶„ì„í•  ì´ë¯¸ì§€ê°€ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        if not self.ocr_reader_instance and not easyocr: 
             QMessageBox.critical(self, "EasyOCR ì˜¤ë¥˜", "EasyOCR ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ê±°ë‚˜ ë¡œë“œì— ì‹¤íŒ¨í•˜ì—¬ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
             return
        if not self.llm_model_instance and not GPT4All: 
             QMessageBox.critical(self, "GPT4All ì˜¤ë¥˜", "GPT4All ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ê±°ë‚˜ ë¡œë“œì— ì‹¤íŒ¨í•˜ì—¬ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
             return
        if not cv2:
            QMessageBox.critical(self, "OpenCV ì˜¤ë¥˜", "OpenCV(cv2) ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ ì´ë¯¸ì§€ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        self.raw_ocr_text = "" 
        self.current_corrected_text = ""
        self._start_background_worker("ocr_correct", image_path=self.current_image_path)

    def run_explanation_task(self, text_for_explanation):
        if not text_for_explanation:
            self.update_status_message("ì˜¤ë¥˜: í•´ì„¤í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        if not self.llm_model_instance and not GPT4All:
             QMessageBox.critical(self, "GPT4All ì˜¤ë¥˜", "GPT4All ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ê±°ë‚˜ ë¡œë“œì— ì‹¤íŒ¨í•˜ì—¬ í•´ì„¤ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
             return
        self._start_background_worker("explain", text_input=text_for_explanation)

    def handle_worker_result(self, task_type, data):
        if task_type == "ocr_result":
            self.raw_ocr_text = data
            self.update_status_message("OCR ì¶”ì¶œ ì™„ë£Œ. LLMìœ¼ë¡œ ì •ì œ ì¤‘...")
        elif task_type == "corrected_text_result":
            self.current_corrected_text = data
            self.update_status_message("LLM ì •ì œ ì™„ë£Œ. ê²°ê³¼ í™•ì¸ ë° ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰ ê°€ëŠ¥.")
            self.show_comparison_dialog()
        elif task_type == "explanation_result":
            self.show_explanation_dialog(data)
            self.update_status_message("ë¬¸ì„œ í•´ì„¤ ì™„ë£Œ.")
        
    def handle_worker_progress(self, task_type, value):
        self.progress_bar.setValue(value)

    def handle_worker_finished(self):
        if self.current_worker_runnable and self.current_worker_runnable.task_type != "corrected_text_result":
             self.progress_bar.setValue(100) 
        
        self.set_buttons_for_task_running_state(False)
        self.current_worker_runnable = None 
        self.stop_current_worker_event = None

    def handle_worker_error(self, error_message):
        self.update_status_message(f"ì˜¤ë¥˜ ë°œìƒ: {error_message.splitlines()[0]}") 
        QMessageBox.critical(self, "ì‘ì—… ì˜¤ë¥˜", f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n{error_message}")
        self.progress_bar.setValue(0)
        self.set_buttons_for_task_running_state(False)
        self.current_worker_runnable = None
        self.stop_current_worker_event = None
        self.reset_ui_after_task(full_reset=True)


    def set_buttons_for_task_running_state(self, is_running):
        self.analyze_button.setEnabled(not is_running and bool(self.current_image_path))
        self.cancel_task_button.setEnabled(True) 
        self.select_image_button.setEnabled(not is_running)


    def show_comparison_dialog(self):
        if not self.current_image_path: 
            self.update_status_message("ì˜¤ë¥˜: ë¹„êµí•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            self.reset_ui_after_task(full_reset=True)
            return 

        dialog = ComparisonDialog(self.current_image_path, self.raw_ocr_text, self.current_corrected_text, self)
        dialog_result = dialog.exec()

        if dialog_result == 1: # Redo
            self.update_status_message("ì¬ì‹œë„ ìš”ì²­ë¨. ì´ë¯¸ì§€ ë¶„ì„ì„ ë‹¤ì‹œ ì‹œì‘í•©ë‹ˆë‹¤.")
            self.run_ocr_correction_task()
        elif dialog_result == 2: # Accept
            self.final_accepted_text_for_explanation = dialog.get_accepted_text()
            if self.final_accepted_text_for_explanation and self.final_accepted_text_for_explanation.strip():
                self.update_status_message("ì •ì œëœ í…ìŠ¤íŠ¸ ìˆ˜ë½ë¨. ë¬¸ì„œ í•´ì„¤ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                self.run_explanation_task(self.final_accepted_text_for_explanation)
            else:
                QMessageBox.warning(self, "í…ìŠ¤íŠ¸ ì—†ìŒ", "í•´ì„¤ì„ ìœ„í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                self.reset_ui_after_task() 
        else: # Cancel or closed
            self.update_status_message("ë¹„êµ ì‘ì—… ì·¨ì†Œë¨. ì´ˆê¸° ìƒíƒœë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.")
            self.reset_ui_after_task(full_reset=True) 
            
    def show_explanation_dialog(self, explanation_text):
        dialog = ExplanationDialog(explanation_text, self)
        dialog.exec()
        self.reset_ui_after_task(full_reset=True) 

    def cancel_current_worker_if_running(self):
        if self.current_worker_runnable and self.stop_current_worker_event:
            self.update_status_message("í˜„ì¬ ì‘ì—… ì¤‘ì§€ ì‹œë„ ì¤‘...")
            self.stop_current_worker_event.set()
            self.current_worker_runnable = None 
            self.stop_current_worker_event = None 
            self.set_buttons_for_task_running_state(False)
            self.progress_bar.setValue(0)
            return True
        return False

    def cancel_or_reset_all_processes(self):
        if self.cancel_current_worker_if_running():
             self.update_status_message("ì§„í–‰ ì¤‘ì¸ ì‘ì—…ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
        else:
            self.update_status_message("ì´ˆê¸°í™” ì™„ë£Œ.")
        self.reset_ui_after_task(full_reset=True)

    def reset_ui_after_task(self, full_reset=False):
        self.progress_bar.setValue(0)
        self.raw_ocr_text = ""
        self.current_corrected_text = ""
        self.final_accepted_text_for_explanation = ""
        
        if full_reset:
            self.current_image_path = None
            self.image_display_label.setText("ì´ë¯¸ì§€ë¥¼ ì—¬ê¸°ì— ë“œë˜ê·¸ ì•¤ ë“œë¡­ í•˜ê±°ë‚˜ ìœ„ ë²„íŠ¼ìœ¼ë¡œ ì„ íƒí•˜ì„¸ìš”.")
            self.image_display_label.setPixmap(QPixmap()) 
            self.analyze_button.setEnabled(False)
            self.update_status_message("ì´ˆê¸°í™” ì™„ë£Œ. ìƒˆ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        else: 
            self.analyze_button.setEnabled(bool(self.current_image_path))
            self.update_status_message("ì‘ì—… ì™„ë£Œ. ë‹¤ìŒ ë¶„ì„ì„ ì§„í–‰í•˜ê±°ë‚˜ ìƒˆ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”.")

        self.set_buttons_for_task_running_state(False)


    def closeEvent(self, event):
        self.update_status_message("ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì¤‘...")
        self.cancel_current_worker_if_running()
        print("ìŠ¤ë ˆë“œ í’€ ì •ë¦¬ ì‹œë„...")
        self.threadpool.waitForDone(2000) 
        print("ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œë¨.")
        super().closeEvent(event)

if __name__ == '__main__':
    if not easyocr or not GPT4All or not cv2:
        app_temp = QApplication.instance() 
        if app_temp is None:
            app_temp = QApplication(sys.argv) 
        
        missing_libs = []
        if not easyocr: missing_libs.append("EasyOCR")
        if not GPT4All: missing_libs.append("GPT4All")
        if not cv2: missing_libs.append("OpenCV (cv2)")

        error_dialog = QMessageBox()
        error_dialog.setIcon(QMessageBox.Icon.Critical)
        error_dialog.setWindowTitle("ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤ë¥˜")
        error_dialog.setText(f"í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ({', '.join(missing_libs)})ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        error_dialog.setInformativeText("í„°ë¯¸ë„ì—ì„œ í•´ë‹¹ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\n"
                                       "(ì˜ˆ: pip install easyocr gpt4all opencv-python)\n"
                                       "ì´ë¯¸ ì„¤ì¹˜í–ˆë‹¤ë©´, ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ë˜ëŠ” í™˜ê²½ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        error_dialog.setStandardButtons(QMessageBox.StandardButton.Ok)
        error_dialog.exec()
        sys.exit(1)

    app = QApplication(sys.argv)
    window = MainWindow()
    window.show()
    sys.exit(app.exec())
